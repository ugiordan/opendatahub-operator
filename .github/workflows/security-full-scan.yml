name: Security Full Codebase Scan

# Version: v2.3.0
# Last Updated: 2026-01-29
# Plugin: security-findings-manager
# Description: Comprehensive security scanning with 9 specialized tools

# This workflow performs comprehensive security scanning on the ENTIRE codebase.
# Complements CodeRabbit's PR incremental scanning with full repository validation.
#
# Trigger modes:
# - Manual: workflow_dispatch (on-demand PoC testing)
# - Scheduled: Weekly on Sundays at 00:00 UTC (optional baseline)
# - On-demand: Can be triggered via GitHub UI or gh CLI

on:
  workflow_dispatch:  # Manual trigger via GitHub UI or gh CLI
    inputs:
      test_advisory:
        description: 'Test security advisory creation (creates advisory even with no findings)'
        required: false
        type: boolean
        default: false
      scan_git_history:
        description: 'Scan full git history for secrets (slower, may find secrets in deleted files)'
        required: false
        type: boolean
        default: false
  schedule:
    # Run weekly on Sunday at 00:00 UTC for baseline tracking
    - cron: '0 0 * * 0'

jobs:
  security-scan:
    name: Full Codebase Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write          # For SARIF upload

    steps:
      - name: Checkout repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8  # v6.0.1
        with:
          fetch-depth: 0  # Full history for accurate analysis

      # ============================================================================
      # BASELINE FETCH FROM GITHUB SECRETS (MANDATORY)
      # ============================================================================
      # Fetch security baseline from GitHub Secrets (compressed)
      # Baseline contains acknowledged findings (false positives/accepted risks)
      # Loaded into SECURITY_BASELINE environment variable for in-memory processing
      # NO FILE FALLBACK - GitHub Secret is mandatory for security

      - name: Load baseline from GitHub Secret
        id: load-baseline
        env:
          BASELINE_COMPRESSED: ${{ secrets.SECURITY_BASELINE }}
        run: |
          if [ -z "$BASELINE_COMPRESSED" ]; then
            echo "‚ÑπÔ∏è  SECURITY_BASELINE secret not found"
            echo "   Creating empty baseline for first-time setup..."
            echo ""

            # Create empty baseline for first scan
            cat > /tmp/baseline.yaml <<'EOF'
          version: "2.0"
          description: "Acknowledged security findings"
          _comment: "First-time setup - empty baseline. Use /sec-scan:acknowledge to add acknowledgments."
          gitleaks: []
          trufflehog: []
          semgrep: []
          shellcheck: []
          hadolint: []
          yamllint: []
          actionlint: []
          kube-linter: []
          rbac-analyzer: []
          EOF

            echo "‚úÖ Created empty baseline (first-time setup)"
            echo ""
            echo "After this scan completes, you can:"
            echo "  1. Run /sec-scan:acknowledge to review and acknowledge findings"
            echo "  2. Updated baseline will be stored in SECURITY_BASELINE secret"
            echo ""
          else
            # Decompress existing baseline
            echo "üîç Loading baseline from SECURITY_BASELINE secret..."

            # NOTE: Can't use command substitution $() because gzip output has null bytes
            # which bash strips. Must use temporary file.
            set -euo pipefail
            if ! echo "$BASELINE_COMPRESSED" | base64 -d | gunzip > /tmp/baseline.yaml; then
              echo "::error::Failed to decompress SECURITY_BASELINE secret - invalid format"
              echo ""
              echo "‚ùå ERROR: Failed to decompress baseline from SECURITY_BASELINE secret"
              echo ""
              echo "Possible causes:"
              echo "  1. Secret contains invalid base64 encoding"
              echo "  2. Secret contains corrupted gzip data"
              echo "  3. Secret was manually edited incorrectly"
              echo ""
              echo "To fix, regenerate the secret:"
              echo "  1. Get the baseline YAML file"
              echo "  2. Compress and encode: cat baseline.yaml | gzip | base64 -w 0 > baseline-compressed.txt"
              echo "  3. Update secret: gh secret set SECURITY_BASELINE -b \"\$(cat baseline-compressed.txt)\" --repo ${{ github.repository }}"
              exit 1
            fi
            set +euo pipefail

            echo "‚úÖ Loaded baseline from SECURITY_BASELINE secret"
          fi

          # Validate baseline YAML structure before using
          echo "üîç Validating baseline structure..."
          python3 << 'EOF'
          import yaml
          import sys

          try:
              with open('/tmp/baseline.yaml') as f:
                  data = yaml.safe_load(f)

              # Validate required structure
              if not isinstance(data, dict):
                  print("‚ùå ERROR: Baseline is not a dictionary")
                  sys.exit(1)

              if 'version' not in data:
                  print("‚ùå ERROR: Baseline missing 'version' field")
                  sys.exit(1)

              # Validate all tool keys are lists
              required_tools = ['gitleaks', 'trufflehog', 'semgrep', 'shellcheck',
                                'hadolint', 'yamllint', 'actionlint', 'kube-linter', 'rbac-analyzer']
              for tool in required_tools:
                  if tool in data and not isinstance(data[tool], list):
                      print(f"‚ùå ERROR: Baseline['{tool}'] must be a list, got {type(data[tool]).__name__}")
                      sys.exit(1)

              print(f"‚úÖ Baseline validation passed (version {data.get('version')})")
          except yaml.YAMLError as e:
              print(f"‚ùå ERROR: Invalid YAML syntax in baseline")
              print(f"   {str(e)}")
              sys.exit(1)
          except Exception as e:
              print(f"‚ùå ERROR: Baseline validation failed: {e}")
              sys.exit(1)
          EOF

          # Export as environment variable for subsequent steps
          echo "BASELINE_YAML<<EOF" >> $GITHUB_ENV
          cat /tmp/baseline.yaml >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

          # Read baseline for size calculations
          BASELINE_YAML=$(cat /tmp/baseline.yaml)

          # Show size info
          SIZE=$(echo "$BASELINE_YAML" | wc -c | tr -d ' ')
          # Use the already-compressed secret size instead of re-compressing (performance optimization)
          COMPRESSED_SIZE=$(echo "$BASELINE_COMPRESSED" | wc -c | tr -d ' ')
          FINDINGS=$(echo "$BASELINE_YAML" | grep -c "hash:" || echo "0")

          echo "‚úÖ Loaded baseline from GitHub Secret"
          echo "   Findings: $FINDINGS"
          echo "   Size: $SIZE bytes (uncompressed)"
          echo "   Size: $COMPRESSED_SIZE bytes (compressed)"
          echo "   GitHub Secret Limit: 49,152 bytes"

          PERCENT=$((COMPRESSED_SIZE * 100 / 49152))
          echo "   Usage: ${PERCENT}%"

          # Export size metrics for later steps
          echo "BASELINE_SIZE_COMPRESSED=$COMPRESSED_SIZE" >> $GITHUB_ENV
          echo "BASELINE_SIZE_PERCENT=$PERCENT" >> $GITHUB_ENV

          # Threshold checks for baseline size monitoring
          # 45000 bytes = ~91.5% of 49152 limit (critical warning threshold)
          # 39321 bytes = ~80% of 49152 limit (monitoring threshold)
          if [ $COMPRESSED_SIZE -gt 45000 ]; then
            echo "‚ö†Ô∏è  WARNING: Approaching GitHub secret size limit!"
            echo "   Current usage: ${PERCENT}% (${COMPRESSED_SIZE} / 49,152 bytes)"
            echo ""
            echo "üí° Cleanup suggestions:"
            echo "   1. Remove acknowledgments for findings that no longer exist in codebase"
            echo "   2. Archive old baselines (download and save to secure storage)"
            echo "   3. Review and consolidate duplicate acknowledgments"
            echo ""
            echo "   To review baseline content, run:"
            echo "   gh secret get SECURITY_BASELINE --repo ${{ github.repository }} | base64 -d | gunzip"
          elif [ $COMPRESSED_SIZE -gt 39321 ]; then
            echo "‚ÑπÔ∏è  Baseline usage at ${PERCENT}% - monitoring recommended"
            echo "   Consider periodic cleanup to prevent hitting size limit"
          fi

      # ============================================================================
      # QUAY.IO CREDENTIALS VALIDATION (EARLY CHECK)
      # ============================================================================
      # Validate Quay.io credentials and namespace access before running scans
      # Fails fast if credentials are missing or incorrect
      # Saves time by not running scans if the final push will fail

      - name: Validate Quay.io credentials and namespace
        id: validate-quay
        env:
          QUAY_ID: ${{ secrets.QUAY_ID }}
          QUAY_ORG: ${{ secrets.QUAY_ORG }}
          QUAY_USER: ${{ secrets.QUAY_USER }}
          QUAY_TOKEN: ${{ secrets.QUAY_TOKEN }}
          SECURITY_QUAY_ORG: ${{ secrets.SECURITY_QUAY_ORG }}
          QUAY_REPO: ${{ secrets.QUAY_REPO }}
        run: |
          echo "üîç Validating Quay.io credentials and namespace..."

          # Determine credentials format (QUAY_ID or QUAY_USER)
          if [ -n "$QUAY_ID" ]; then
            # opendatahub-operator style: QUAY_ID, QUAY_ORG, QUAY_TOKEN
            QUAY_USERNAME="$QUAY_ID"
            QUAY_NAMESPACE="$QUAY_ORG"
          elif [ -n "$QUAY_USER" ]; then
            # Alternative style: QUAY_USER, QUAY_TOKEN
            QUAY_USERNAME="$QUAY_USER"
            # Extract namespace from QUAY_USER (format: "namespace+robot")
            QUAY_NAMESPACE=$(echo "$QUAY_USER" | cut -d+ -f1)
          else
            QUAY_USERNAME=""
            QUAY_NAMESPACE=""
          fi

          # Override namespace for security scans if specified
          if [ -n "$SECURITY_QUAY_ORG" ]; then
            QUAY_NAMESPACE="$SECURITY_QUAY_ORG"
          fi

          # Determine repository name (use centralized security-scans repo)
          # All security scan reports go to the same Quay.io repository with different tags
          # This simplifies permission management (one robot account, one repository)
          if [ -n "$QUAY_REPO" ]; then
            QUAY_REPO_NAME="$QUAY_REPO"
          else
            QUAY_REPO_NAME="security-scans"  # Centralized repository for all security scans
          fi

          # Warn if both secret schemes are configured
          if [ -n "$QUAY_ID" ] && [ -n "$QUAY_USER" ]; then
            echo ""
            echo "‚ö†Ô∏è  WARNING: Both QUAY_ID and QUAY_USER secrets are set"
            echo "   Using QUAY_ID (opendatahub-operator style takes priority)"
            echo "   Consider removing the unused QUAY_USER secret to avoid confusion"
            echo ""
          fi

          # Check if credentials are configured
          if [[ -z "$QUAY_USERNAME" || -z "$QUAY_TOKEN" ]]; then
            echo "::error::Quay.io credentials not configured - QUAY_USER/QUAY_ID or QUAY_TOKEN missing"
            echo ""
            echo "‚ùå ERROR: Quay.io credentials not configured"
            echo ""
            echo "Required GitHub Secrets (choose one format):"
            echo ""
            echo "Format 1 (opendatahub-operator style):"
            echo "  - QUAY_ID: Robot account ID (e.g., 'rhoai-security+github-robot')"
            echo "  - QUAY_ORG: Organization name (e.g., 'rhoai-security')"
            echo "  - QUAY_TOKEN: Robot account token"
            echo ""
            echo "Format 2 (alternative):"
            echo "  - QUAY_USER: Robot account username (e.g., 'namespace+robot-name')"
            echo "  - QUAY_TOKEN: Robot account token"
            echo ""
            echo "Setup instructions:"
            echo "  1. Create Quay.io robot account: https://quay.io/organization/<your-org>?tab=robots"
            echo "  2. Grant write permissions to your organization"
            echo "  3. Add secrets to GitHub repository settings"
            echo "  4. Repository will be auto-created on first push"
            exit 1
          fi

          # Validate namespace is set
          if [ -z "$QUAY_NAMESPACE" ]; then
            echo "::error::Could not determine Quay.io namespace from credentials"
            echo ""
            echo "‚ùå ERROR: Could not determine Quay.io namespace"
            echo "   QUAY_ORG is not set (when using QUAY_ID)"
            echo "   or QUAY_USER format is invalid (should be 'namespace+robot')"
            exit 1
          fi

          echo "   Username: $QUAY_USERNAME"
          echo "   Namespace: $QUAY_NAMESPACE"

          # Test Quay.io login
          echo ""
          echo "üîê Testing Quay.io authentication..."
          LOGIN_OUTPUT=$(echo "$QUAY_TOKEN" | podman login quay.io -u "$QUAY_USERNAME" --password-stdin 2>&1) || {
            echo "::error::Quay.io authentication failed for user: $QUAY_USERNAME"
            echo ""
            echo "‚ùå ERROR: Quay.io authentication failed"
            echo "   Username: $QUAY_USERNAME"
            echo ""
            echo "Podman error output:"
            echo "$LOGIN_OUTPUT" | sed 's/^/   /'
            echo ""
            echo "Possible causes:"
            echo "  1. Invalid robot account credentials"
            echo "  2. Robot account has been deleted or disabled"
            echo "  3. Token has expired or been revoked"
            echo "  4. Network connectivity issues"
            echo ""
            echo "To fix:"
            echo "  1. Verify robot account exists: https://quay.io/organization/${QUAY_NAMESPACE}?tab=robots"
            echo "  2. Regenerate token if needed"
            echo "  3. Update GitHub secret: gh secret set QUAY_TOKEN --repo ${{ github.repository }}"
            exit 1
          }

          echo "‚úÖ Quay.io authentication successful"

          # Check if repository exists or if we have permission to create it
          REPO_URL="quay.io/${QUAY_NAMESPACE}/${QUAY_REPO_NAME}"

          echo ""
          echo "üì¶ Checking repository access: ${REPO_URL}"

          # Check if skopeo is available (optional check)
          if ! command -v skopeo &> /dev/null; then
            echo "‚ö†Ô∏è  skopeo not installed, skipping repository access check"
            echo "   Repository access will be verified during push"
          else
            # Try to pull repository metadata (doesn't require pulling the image)
            # This checks if the repository exists and we have access
            if skopeo inspect --creds "${QUAY_USERNAME}:${QUAY_TOKEN}" "docker://${REPO_URL}:latest" >/dev/null 2>&1; then
              echo "‚úÖ Repository exists and is accessible"
            else
              echo "‚ÑπÔ∏è  Repository does not exist yet or 'latest' tag not found"
              echo "   Repository will be created on first push"
              echo "   Location: https://${REPO_URL}"
            fi
          fi

          # Export validated values for use in later steps (avoid recalculation)
          echo "quay_namespace=${QUAY_NAMESPACE}" >> $GITHUB_OUTPUT
          echo "quay_username=${QUAY_USERNAME}" >> $GITHUB_OUTPUT
          echo "quay_repo_name=${QUAY_REPO_NAME}" >> $GITHUB_OUTPUT

          echo ""
          echo "‚úÖ Quay.io validation complete"
          echo "   All scans will push reports to: ${REPO_URL}"

      # ============================================================================
      # SECRETS DETECTION - Gitleaks (Pattern-based)
      # ============================================================================
      # Tool: Gitleaks v8.30.0
      # Purpose: Detects hardcoded secrets using regex patterns (API keys, passwords, tokens)
      # Coverage: ~100 built-in patterns for AWS, GitHub, Slack, etc.
      # Mode: Pattern-based detection (fast, some false positives possible)
      # Scope: By default scans current working tree only (--no-git flag)
      #        Set scan_git_history=true to scan full git history (slower, finds historical secrets)
      # Security Trade-off:
      #   - --no-git (default): Fast, low noise, but blind to secrets in deleted commits (CWE-312)
      #   - Full history: Comprehensive, finds all historical secrets, but includes false positives
      #   - Recommendation: Use --no-git for weekly scans, full history for incident response
      # Complement: TruffleHog scans full git history with credential verification
      #
      # Docker Image Pinning:
      # - Git tag: v8.30.0
      # - Docker digest (linux/amd64): sha256:105ac66a57b2bb8afb61a3b8a5dcc4817773d03724a7e8a515214cfe58225556
      # - Why digest?: Immutable reference, prevents tag retargeting attacks
      # - Verification: docker pull --platform linux/amd64 ghcr.io/gitleaks/gitleaks:v8.30.0 && docker inspect ghcr.io/gitleaks/gitleaks:v8.30.0 --format='{{.RepoDigests}}'

      - name: Run Gitleaks secrets scanner
        id: gitleaks
        timeout-minutes: 10
        run: |
          # Conditionally add --no-git flag based on workflow input
          NO_GIT_FLAG="${{ !inputs.scan_git_history && '--no-git' || '' }}"

          docker run --rm \
            -v "${{ github.workspace }}:/repo" \
            ghcr.io/gitleaks/gitleaks@sha256:105ac66a57b2bb8afb61a3b8a5dcc4817773d03724a7e8a515214cfe58225556 \
            detect \
              --source /repo \
              $NO_GIT_FLAG \
              --report-format json \
              --report-path /repo/gitleaks.json \
              --verbose
        continue-on-error: true  # Don't block workflow, collect all findings

      # ============================================================================
      # SECRETS DETECTION - TruffleHog (Verified Credentials)
      # ============================================================================
      # Tool: TruffleHog v3.92.3
      # Purpose: Detects AND verifies live credentials by testing them against APIs
      # Coverage: 800+ credential types with API verification
      # Mode: Verified detection (slower, near-zero false positives)
      # Benefit: Confirms credentials are active/exploitable, not just pattern matches
      # Note: Only runs in full scans (not CodeRabbit PRs) due to API call overhead
      #
      # Docker Image Pinning:
      # - Git tag: 3.92.3
      # - Docker digest (linux/amd64): sha256:e42f126628f0a0ce4ee670bf62b71543eca5a3a2d3c590ff361091b841ac39c1
      # - Why digest?: Immutable reference, prevents tag retargeting attacks
      # - Source: https://github.com/trufflesecurity/trufflehog/pkgs/container/trufflehog
      # - Verification: docker run --rm ghcr.io/trufflesecurity/trufflehog@sha256:e42f126628f0a0ce4ee670bf62b71543eca5a3a2d3c590ff361091b841ac39c1 --version

      - name: Run TruffleHog secrets scanner
        id: trufflehog
        timeout-minutes: 10
        run: |
          docker run --rm \
            -v "${{ github.workspace }}:/repo" \
            ghcr.io/trufflesecurity/trufflehog@sha256:e42f126628f0a0ce4ee670bf62b71543eca5a3a2d3c590ff361091b841ac39c1 \
            filesystem /repo \
              --only-verified \
              --json > trufflehog.json
        continue-on-error: true  # Don't block workflow, collect all findings

      # ============================================================================
      # CUSTOM SECURITY RULES - Semgrep
      # ============================================================================
      # Tool: Semgrep v1.145.0
      # Purpose: Custom SAST rules for RBAC, OWASP, Kubernetes operator patterns
      # Coverage: 27 operator-focused rules (11 RBAC, excludes SQL/command injection)
      # Config: semgrep.yaml in repository root
      # Output: SARIF format for GitHub Security tab integration
      #
      # Docker Image Pinning:
      # - Git tag: v1.145.0
      # - Docker digest (linux/amd64): sha256:1f0850c540140c6da68811b21012fd26e91e5323daae245b0a71e70b72a89d2a
      # - Why digest?: Immutable reference, prevents Docker Hub tag retargeting attacks
      # - Verification: podman manifest inspect semgrep/semgrep:1.145.0 | jq -r '.manifests[] | select(.platform.architecture=="amd64") | .digest'

      - name: Run Semgrep security analysis
        id: semgrep
        run: |
          docker run --rm \
            -v "${{ github.workspace }}:/src" \
            -e SEMGREP_TIMEOUT=300 \
            semgrep/semgrep@sha256:1f0850c540140c6da68811b21012fd26e91e5323daae245b0a71e70b72a89d2a \
            semgrep scan \
              --config /src/semgrep.yaml \
              --sarif \
              --output /src/semgrep.sarif \
              /src
        continue-on-error: true

      - name: Upload Semgrep SARIF results
        if: always() && hashFiles('semgrep.sarif') != ''
        uses: github/codeql-action/upload-sarif@1b168cd39490f61582a9beae412bb7057a6b2c4e  # v4.31.8
        with:
          sarif_file: semgrep.sarif
          category: semgrep

      # ============================================================================
      # SHELL SCRIPT SECURITY - ShellCheck
      # ============================================================================
      # Tool: ShellCheck v0.10.0
      # Purpose: Static analysis for shell scripts (bash, sh)
      # Detects: Quoting issues, command injection, dangerous patterns
      # Coverage: ALL .sh files including CI/CD, build scripts, and examples
      # Common findings: Unquoted variables, missing error handling, SC2086, SC2046
      # OWASP: Prevents CWE-78 (OS Command Injection)
      # Note: Scans all scripts intentionally - build/CI scripts are attack vectors

      - name: Install ShellCheck
        run: |
          sudo apt-get update
          sudo apt-get install -y shellcheck

      - name: Run ShellCheck
        id: shellcheck
        run: |
          # Find all shell scripts and run shellcheck, outputting JSON
          # Scans ALL scripts including .github/scripts, hack/, tests/
          # Excludes only vendor/ to avoid third-party code noise
          find . -name "*.sh" -type f -not -path "*/vendor/*" -print0 | \
            xargs -0 shellcheck --format=json --severity=warning > shellcheck.json
        continue-on-error: true

      # ============================================================================
      # DOCKERFILE SECURITY - Hadolint
      # ============================================================================
      # Tool: Hadolint v3.3.0
      # Purpose: Dockerfile linter enforcing best practices
      # Detects: Secrets in ENV, unpinned base images, running as root
      # Coverage: All Dockerfile* files (including Dockerfile.dev, etc.)
      # Standards: Enforces Docker best practices and CIS Benchmark recommendations
      # Output: SARIF format for GitHub Security tab integration

      - name: Run Hadolint on Dockerfiles
        id: hadolint
        uses: hadolint/hadolint-action@2332a7b74a6de0dda2e2221d575162eba76ba5e5  # v3.3.0
        with:
          recursive: true
          format: sarif
          output-file: hadolint.sarif
        continue-on-error: true

      - name: Upload Hadolint SARIF results
        if: always() && hashFiles('hadolint.sarif') != ''
        uses: github/codeql-action/upload-sarif@1b168cd39490f61582a9beae412bb7057a6b2c4e  # v4.31.8
        with:
          sarif_file: hadolint.sarif
          category: hadolint

      # ============================================================================
      # YAML VALIDATION - yamllint
      # ============================================================================
      # Tool: yamllint v1.37.1
      # Purpose: Validates YAML syntax and style for Kubernetes manifests
      # Detects: Syntax errors, inconsistent indentation, line length violations
      # Config: .yamllint (strict truthy checking: yes/no/true/false enforcement)
      # Coverage: All .yaml and .yml files (manifests, workflows, configs)
      # Benefit: Catches deployment-breaking YAML errors before runtime
      # Output: parsable format (file:line:col: [level] message (rule))
      # Note: JSON format not supported - PR #245 never merged

      - name: Install yamllint
        run: |
          python -m pip install --upgrade pip
          pip install yamllint==1.37.1

      - name: Run yamllint
        id: yamllint
        run: |
          yamllint -f parsable . > yamllint.txt || true
        continue-on-error: true

      # ============================================================================
      # GITHUB ACTIONS WORKFLOW VALIDATION - actionlint
      # ============================================================================
      # Tool: actionlint v1.7.8
      # Purpose: Validates GitHub Actions workflow syntax and best practices
      # Detects: Invalid expressions, incorrect job dependencies, unsafe permissions
      # Coverage: All .github/workflows/*.yml files
      # Benefit: Catches workflow-specific issues that yamllint doesn't validate
      # Complements: yamllint (general YAML) + Semgrep (secrets/security)
      # Output: Human-readable format with color highlighting
      #
      # Docker Image Pinning:
      # - Git tag: v1.7.8
      # - Docker digest (linux/amd64): sha256:32a5c57cebdc2aad2ca4083dcdf08a784795b06adde2082fd2ef724445582390
      # - Why digest?: Immutable reference, prevents tag retargeting attacks
      # - Verification: docker pull rhysd/actionlint:1.7.8 && docker inspect rhysd/actionlint:1.7.8 --format='{{.RepoDigests}}'

      - name: Run actionlint on GitHub Actions workflows
        id: actionlint
        timeout-minutes: 5
        run: |
          docker run --rm \
            -v "${{ github.workspace }}:/repo" \
            -w /repo \
            rhysd/actionlint@sha256:32a5c57cebdc2aad2ca4083dcdf08a784795b06adde2082fd2ef724445582390 \
            --no-color > actionlint.txt 2>&1
        continue-on-error: true

      # ============================================================================
      # KUBERNETES MANIFEST SECURITY - kube-linter
      # ============================================================================
      # Tool: kube-linter v0.8.1
      # Purpose: Kubernetes manifest validation for security and best practices
      # Coverage: 36 security checks (up from 9 original checks):
      #   - Container security (13 checks): privilege escalation, host namespaces,
      #     docker.sock, sensitive mounts, capabilities, sysctls
      #   - RBAC (5 checks): CIS Benchmark 5.1.1-5.1.4 (cluster-admin, secrets,
      #     wildcards, pod creation)
      #   - Secret management (2 checks): CIS 5.4.1 (env vars vs mounted secrets)
      #   - Service Account (2 checks): default SA, non-existent SA
      #   - Network security (4 checks): privileged ports, SSH, exposed services,
      #     NetworkPolicy isolation
      #   - Reliability (4 checks): liveness/readiness probes, resource limits
      #   - Namespace isolation (1 check): CIS 5.7.1, 5.7.4 (default namespace)
      #   - Image security (1 check): latest tag prohibition
      # Config: .kube-linter.yaml (36 checks total, organized by category)
      # Output: SARIF (GitHub Security tab) + JSON (comprehensive report)
      # Scope: Rendered Kubernetes manifests from kustomize build
      #
      # Integration Notes:
      # - Complements RBAC Analyzer: kube-linter checks individual RBAC rules,
      #   RBAC Analyzer maps full privilege chains (Pod‚ÜíSA‚ÜíRole‚ÜíBinding)
      # - Runs in both PR workflow (test-linter.yaml) and weekly full scan

      - name: Install kube-linter
        if: hashFiles('go.mod') != '' || hashFiles('Makefile') != ''
        run: |
          # Install pre-built binary from GitHub Releases (avoids supply chain risk)
          # Using official release instead of go run module@version
          set -euo pipefail
          KUBE_LINTER_VERSION="v0.8.1"
          KUBE_LINTER_ASSET="kube-linter-linux.tar.gz"
          KUBE_LINTER_URL="https://github.com/stackrox/kube-linter/releases/download/${KUBE_LINTER_VERSION}/kube-linter-linux.tar.gz"
          KUBE_LINTER_SHA256="49629abaf0ae3283e9437214a2bea4bf4029008744e05471c85dd3872464f50b"

          curl -sSfL --max-time 300 -o "${KUBE_LINTER_ASSET}" "${KUBE_LINTER_URL}"
          echo "${KUBE_LINTER_SHA256}  ${KUBE_LINTER_ASSET}" | sha256sum -c -
          tar -xzf "${KUBE_LINTER_ASSET}" kube-linter
          sudo mv kube-linter /usr/local/bin/
          kube-linter version
          rm -f "${KUBE_LINTER_ASSET}"

      - name: Set up Go for kustomize
        if: hashFiles('go.mod') != ''
        uses: actions/setup-go@44694675825211faa026b3c33043df3e48a5fa00  # v6.0.0
        with:
          go-version-file: go.mod

      - name: Run kube-linter
        if: hashFiles('go.mod') != '' || hashFiles('Makefile') != ''
        id: kubelinter
        timeout-minutes: 5
        run: |
          # Prepare kustomize and render manifests
          make prepare
          TMP_FILE=$(mktemp /tmp/kube-lint.XXXXXX.yaml)
          ./bin/kustomize build config/manifests > "$TMP_FILE"

          # Run kube-linter with JSON output for comprehensive report
          # Capture exit code separately from output to distinguish scanner errors from findings
          set +e  # Don't exit on non-zero
          kube-linter lint \
            --config .kube-linter.yaml \
            --format json \
            "$TMP_FILE" > kube-linter.json
          JSON_EXIT=$?
          set -e

          # Run kube-linter with SARIF output for GitHub Security tab
          set +e
          kube-linter lint \
            --config .kube-linter.yaml \
            --format sarif \
            "$TMP_FILE" > kube-linter.sarif 2>kube-linter.stderr
          SARIF_EXIT=$?
          set -e

          # Validate outputs - empty/invalid output means scanner failed, not "no findings"
          if [ $JSON_EXIT -ne 0 ] && [ ! -s kube-linter.json ]; then
            echo "‚ùå kube-linter JSON output failed or empty (exit: $JSON_EXIT)"
            echo "::warning::kube-linter failed to produce valid JSON output"
            exit 1
          fi

          # If JSON is valid and contains findings, exit non-zero so summary shows "Issues Found"
          if [ -s kube-linter.json ] && jq -e . >/dev/null 2>&1 < kube-linter.json; then
            findings_count=$(jq '.Reports | length' kube-linter.json 2>/dev/null || echo 0)
            if [ "${findings_count:-0}" -gt 0 ]; then
              exit 1
            fi
          else
            if [ -f kube-linter.json ]; then
              echo "::warning::kube-linter produced invalid JSON"
              exit 1
            fi
          fi

          if [ $SARIF_EXIT -ne 0 ] && [ ! -s kube-linter.sarif ]; then
            echo "‚ùå kube-linter SARIF output failed or empty (exit: $SARIF_EXIT)"
            cat kube-linter.stderr || true
            echo "::warning::kube-linter failed to produce valid SARIF output"
          fi

          rm -f "$TMP_FILE" kube-linter.stderr
        continue-on-error: true

      - name: Upload kube-linter SARIF results
        if: always() && hashFiles('kube-linter.sarif') != ''
        uses: github/codeql-action/upload-sarif@1b168cd39490f61582a9beae412bb7057a6b2c4e  # v4.31.8
        with:
          sarif_file: kube-linter.sarif
          category: kube-linter

      # ============================================================================
      # RBAC PRIVILEGE CHAIN ANALYSIS - Custom Script
      # ============================================================================
      # Tool: Custom Python analyzer (.github/scripts/rbac-analyzer.py)
      # Purpose: Maps privilege escalation chains in Kubernetes RBAC
      # Analysis: ClusterRole ‚Üí RoleBinding ‚Üí ServiceAccount ‚Üí Pod relationships
      # Detects:
      #   - Dangerous verbs (escalate, impersonate, bind)
      #   - Dangerous resources (secrets, pods/exec, pods/attach)
      #   - Wildcard permissions (*, resources/verbs)
      #   - Escalation combos (create/patch/update on roles/bindings)
      #   - Pods with cluster-admin access
      #   - RoleBinding ‚Üí ClusterRole misuse (namespace privilege escalation)
      # Output: Structured findings with CRITICAL/HIGH/WARNING/INFO severity
      # Exit codes: Configurable via --fail-on (production: HIGH, fails on HIGH+ findings)
      # Exclusions: test, examples, docs, bin, .github/workflows
      #
      # Why custom?: No existing tool maps full Pod‚ÜíSA‚ÜíRole privilege chains
      # Complement: Semgrep catches individual RBAC issues, this finds relationships

      - name: Setup Python for RBAC Analysis
        if: hashFiles('.github/scripts/rbac-analyzer.py') != '' || hashFiles('config/**/*.yaml', 'manifests/**/*.yaml', 'kustomize/**/*.yaml', 'overlays/**/*.yaml', 'base/**/*.yaml') != ''
        uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548  # v6.1.0
        with:
          python-version: '3.11'

      - name: Install PyYAML for RBAC analyzer
        if: hashFiles('.github/scripts/rbac-analyzer.py') != '' || hashFiles('config/**/*.yaml', 'manifests/**/*.yaml', 'kustomize/**/*.yaml', 'overlays/**/*.yaml', 'base/**/*.yaml') != ''
        run: python -m pip install "pyyaml==6.0.3"

      - name: Run RBAC Privilege Chain Analyzer (Public Version)
        if: hashFiles('.github/scripts/rbac-analyzer.py') != '' || hashFiles('config/**/*.yaml', 'manifests/**/*.yaml', 'kustomize/**/*.yaml', 'overlays/**/*.yaml', 'base/**/*.yaml') != ''
        id: rbac_analyzer
        run: |
          # Generate public version (no attack scenarios) for artifacts
          python .github/scripts/rbac-analyzer.py . --fail-on HIGH 2>&1 | tee rbac-analysis.md
          echo "## üîê RBAC Privilege Chain Analysis (Public)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat rbac-analysis.md >> $GITHUB_STEP_SUMMARY
        continue-on-error: true

      - name: Generate RBAC Analysis with Attack Scenarios (Private Version)
        if: always() && (hashFiles('.github/scripts/rbac-analyzer.py') != '' || hashFiles('config/**/*.yaml', 'manifests/**/*.yaml', 'kustomize/**/*.yaml', 'overlays/**/*.yaml', 'base/**/*.yaml') != '')
        id: rbac_analyzer_private
        run: |
          # Generate private version with detailed attack scenarios for security advisory
          python .github/scripts/rbac-analyzer.py . --fail-on HIGH --include-attack-scenarios 2>&1 | tee rbac-analysis-private.md
          echo "‚úÖ Private RBAC analysis with attack scenarios generated (for security advisory)"
        continue-on-error: true

      # NOTE: RBAC analysis report upload to artifacts removed for security
      # Reports are stored in Quay.io with RBAC-controlled access
      # Use /get-report command to retrieve reports

      # ============================================================================
      # COMPREHENSIVE SECURITY REPORT GENERATION
      # ============================================================================
      # Tool: Custom Python report generator (.github/scripts/generate-security-report.py)
      # Purpose: Aggregates all tool outputs into a unified markdown report
      # Inputs: JSON/SARIF from all tools (Gitleaks, TruffleHog, Semgrep, etc.)
      # Output: Comprehensive markdown report with:
      #   - Executive summary with overall security posture
      #   - Findings organized by severity (CRITICAL/HIGH/MEDIUM/LOW/INFO)
      #   - File paths, line numbers, descriptions, remediation guidance
      #   - RBAC privilege chain analysis inclusion
      #   - Prioritized recommendations
      # Format: Markdown suitable for security review and JIRA attachments
      # Artifact: Uploaded with org-configured retention period

      - name: Generate comprehensive security report
        if: always()
        env:
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_SHA: ${{ github.sha }}
          GITHUB_REF_NAME: ${{ github.ref_name }}
          GITHUB_SERVER_URL: ${{ github.server_url }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          SECURITY_BASELINE: ${{ env.BASELINE_YAML }}
        run: |
          python .github/scripts/generate-security-report.py \
            --output security-report.md \
            --json-summary security-summary.json \
            --yamllint-report yamllint-report.md \
            --workspace . \
            --yamllint-limit 30
          echo "## Comprehensive Security Report Generated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "A detailed security report has been generated and will be pushed to Quay.io." >> $GITHUB_STEP_SUMMARY
          echo "Reports are stored securely in Quay.io with RBAC-controlled access." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "To retrieve reports, use the \`/sec-scan:show-report\` command or see push step output for exact image tags." >> $GITHUB_STEP_SUMMARY
        continue-on-error: true

      # ============================================================================
      # REPORT INTEGRITY VERIFICATION
      # ============================================================================
      # Generate SHA256 checksums for all report files
      # Checksums stored alongside reports in container image
      # Allows verification of report integrity after retrieval

      - name: Copy baseline for user download
        if: always()
        run: |
          # Copy baseline to working directory so users can download it via artifacts
          # This is needed for the /sec-scan:acknowledge workflow - users need the current baseline
          if [ -f /tmp/baseline.yaml ]; then
            cp /tmp/baseline.yaml security-baseline.yaml
            echo "‚úÖ Copied baseline.yaml for artifact download"
          else
            echo "‚ö†Ô∏è  Warning: baseline.yaml not found in /tmp (this shouldn't happen)"
          fi

      - name: Generate report checksums
        if: always() && hashFiles('security-report.md') != ''
        run: |
          echo "üîí Generating integrity checksums for reports..."

          # Generate checksums for all report files
          sha256sum security-report.md > security-report.md.sha256
          sha256sum security-summary.json > security-summary.json.sha256
          [ -f security-baseline.yaml ] && sha256sum security-baseline.yaml > security-baseline.yaml.sha256

          # Generate checksums for tool-specific reports (if they exist)
          [ -f gitleaks-report.json ] && sha256sum gitleaks-report.json > gitleaks-report.json.sha256
          [ -f trufflehog-report.json ] && sha256sum trufflehog-report.json > trufflehog-report.json.sha256
          [ -f semgrep.sarif ] && sha256sum semgrep.sarif > semgrep.sarif.sha256
          [ -f shellcheck-report.json ] && sha256sum shellcheck-report.json > shellcheck-report.json.sha256
          [ -f hadolint.sarif ] && sha256sum hadolint.sarif > hadolint.sarif.sha256
          [ -f yamllint-report.md ] && sha256sum yamllint-report.md > yamllint-report.md.sha256
          [ -f actionlint.txt ] && sha256sum actionlint.txt > actionlint.txt.sha256
          [ -f kube-linter-report.json ] && sha256sum kube-linter-report.json > kube-linter-report.json.sha256
          [ -f rbac-analysis.md ] && sha256sum rbac-analysis.md > rbac-analysis.md.sha256

          # Create master checksum file
          cat *.sha256 > CHECKSUMS.sha256 2>/dev/null || true

          # Create placeholder files for any missing reports (ensures COPY won't fail)
          for file in gitleaks-report.json trufflehog-report.json semgrep.sarif shellcheck-report.json hadolint.sarif yamllint-report.md actionlint.txt kube-linter-report.json rbac-analysis.md security-baseline.yaml; do
            if [ ! -f "$file" ]; then
              echo "# No findings or tool not run" > "$file"
              sha256sum "$file" > "${file}.sha256"
            fi
          done

          echo "‚úÖ Checksums generated for all reports"
          echo ""
          echo "To verify report integrity after retrieval:"
          echo "  sha256sum -c security-report.md.sha256"
        continue-on-error: true

      # NOTE: GitHub artifacts upload removed for security
      # Reports are ONLY stored in Quay.io (RBAC-controlled)
      # This prevents security reports from being accessible to all repo collaborators

      # ============================================================================
      # QUAY.IO REPORT STORAGE (MANDATORY)
      # ============================================================================
      # Package security reports as container image and push to Quay.io
      # Provides RBAC-controlled access to security reports
      # Reports stored in quay.io/rhoai-security/scans/{repo}:{date}
      # Only authorized teams can access reports (via Quay.io team permissions)

      - name: Package reports as container image
        id: package-reports
        if: always() && hashFiles('security-report.md') != ''
        run: |
          # Create Dockerfile for scratch container with all reports and checksums
          cat > Dockerfile <<'EOF'
          FROM scratch
          # Main reports
          COPY security-report.md /report.md
          COPY security-summary.json /summary.json
          COPY security-baseline.yaml /baseline.yaml

          # Tool-specific reports
          COPY gitleaks-report.json /gitleaks.json
          COPY trufflehog-report.json /trufflehog.json
          COPY semgrep.sarif /semgrep.sarif
          COPY shellcheck-report.json /shellcheck.json
          COPY hadolint.sarif /hadolint.sarif
          COPY yamllint-report.md /yamllint.md
          COPY actionlint.txt /actionlint.txt
          COPY kube-linter-report.json /kube-linter.json
          COPY rbac-analysis.md /rbac-analysis.md

          # Integrity checksums (SHA256)
          COPY security-report.md.sha256 /report.md.sha256
          COPY security-summary.json.sha256 /summary.json.sha256
          COPY security-baseline.yaml.sha256 /baseline.yaml.sha256
          COPY gitleaks-report.json.sha256 /gitleaks.json.sha256
          COPY trufflehog-report.json.sha256 /trufflehog.json.sha256
          COPY semgrep.sarif.sha256 /semgrep.sarif.sha256
          COPY shellcheck-report.json.sha256 /shellcheck.json.sha256
          COPY hadolint.sarif.sha256 /hadolint.sarif.sha256
          COPY yamllint-report.md.sha256 /yamllint.md.sha256
          COPY actionlint.txt.sha256 /actionlint.txt.sha256
          COPY kube-linter-report.json.sha256 /kube-linter.json.sha256
          COPY rbac-analysis.md.sha256 /rbac-analysis.md.sha256
          COPY CHECKSUMS.sha256 /CHECKSUMS.sha256
          EOF

          # Build container image with reports
          REPO_NAME="${{ github.event.repository.name }}"
          DATE_TAG="$(date -u +%Y%m%d-%H%M%S)"
          COMMIT_SHA="${{ github.sha }}"
          SHORT_SHA="${COMMIT_SHA:0:7}"

          # Output values for use in push step
          echo "date_tag=${DATE_TAG}" >> $GITHUB_OUTPUT
          echo "short_sha=${SHORT_SHA}" >> $GITHUB_OUTPUT

          # Reuse namespace and repo name from validation step (already calculated and verified)
          QUAY_NAMESPACE="${{ steps.validate-quay.outputs.quay_namespace }}"
          QUAY_REPO_NAME="${{ steps.validate-quay.outputs.quay_repo_name }}"

          # Output values for use in push step
          echo "quay_namespace=${QUAY_NAMESPACE}" >> $GITHUB_OUTPUT
          echo "quay_repo_name=${QUAY_REPO_NAME}" >> $GITHUB_OUTPUT

          # Build image with two tags (always prefixed with 'scan-' for clarity):
          # 1. scan-{repo}-{date}-{sha} - timestamp + commit correlation
          # 2. scan-{repo}-latest - always get most recent
          BASE_URL="quay.io/${QUAY_NAMESPACE}/${QUAY_REPO_NAME}"

          # Temporarily rename .dockerignore to prevent it from filtering security reports
          # Some repositories have aggressive .dockerignore rules (e.g., **/*.md) that would
          # exclude security-report.md and other report files from the container build context
          if [ -f .dockerignore ]; then
            mv .dockerignore .dockerignore.bak
            echo "‚ÑπÔ∏è  Temporarily renamed .dockerignore to prevent filtering report files"
          fi

          podman build -t "${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA}" .
          podman tag "${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA}" "${BASE_URL}:scan-${REPO_NAME}-latest"

          # Restore .dockerignore
          if [ -f .dockerignore.bak ]; then
            mv .dockerignore.bak .dockerignore
            echo "‚úÖ Restored .dockerignore"
          fi

          echo "üì¶ Built container image with tags:"
          echo "   - ${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA} (timestamp + commit)"
          echo "   - ${BASE_URL}:scan-${REPO_NAME}-latest (most recent)"
        continue-on-error: true

      - name: Push reports to Quay.io
        if: always() && hashFiles('security-report.md') != ''
        env:
          QUAY_TOKEN: ${{ secrets.QUAY_TOKEN }}
        run: |
          # Reuse validated credentials from validate-quay step
          QUAY_USERNAME="${{ steps.validate-quay.outputs.quay_username }}"
          QUAY_NAMESPACE="${{ steps.package-reports.outputs.quay_namespace }}"
          QUAY_REPO_NAME="${{ steps.package-reports.outputs.quay_repo_name }}"

          REPO_NAME="${{ github.event.repository.name }}"
          DATE_TAG="${{ steps.package-reports.outputs.date_tag }}"
          SHORT_SHA="${{ steps.package-reports.outputs.short_sha }}"

          BASE_URL="quay.io/${QUAY_NAMESPACE}/${QUAY_REPO_NAME}"

          # Login to Quay.io (credentials already validated in validate-quay step)
          echo "$QUAY_TOKEN" | podman login quay.io -u "$QUAY_USERNAME" --password-stdin

          # Push both tags (always prefixed with 'scan-')
          podman push "${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA}"
          podman push "${BASE_URL}:scan-${REPO_NAME}-latest"

          echo "‚úÖ Reports pushed to Quay.io:"
          echo "   - ${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA} (timestamp + commit)"
          echo "   - ${BASE_URL}:scan-${REPO_NAME}-latest (most recent)"
          echo ""
          echo "üì• To retrieve reports, use the /get-report command:"
          echo "   /get-report"
          echo ""
          echo "Or manually:"
          echo "   # Pull latest scan:"
          echo "   podman pull ${BASE_URL}:scan-${REPO_NAME}-latest"
          echo ""
          echo "   # Pull specific scan by timestamp + commit:"
          echo "   podman pull ${BASE_URL}:scan-${REPO_NAME}-${DATE_TAG}-${SHORT_SHA}"
          echo ""
          echo "   # Extract reports:"
          echo "   CONTAINER=\$(podman create ${BASE_URL}:scan-${REPO_NAME}-latest)"
          echo "   podman cp \$CONTAINER:/report.md ./security-report.md"
          echo "   podman cp \$CONTAINER:/summary.json ./security-summary.json"
          echo "   podman rm \$CONTAINER"
          echo ""
          echo "üí° Tag Retention Management:"
          echo "   Quay.io supports automatic tag expiration to prevent storage bloat."
          echo "   Consider configuring tag lifecycle policies in Quay.io repository settings:"
          echo ""
          echo "   Recommended policy:"
          echo "   - Keep timestamped tags (scan-${REPO_NAME}-YYYYMMDD-HHMMSS-SHA) for 90 days"
          echo "   - Keep scan-${REPO_NAME}-latest tag indefinitely"
          echo ""
          echo "   Configure at: https://quay.io/repository/${QUAY_NAMESPACE}/${QUAY_REPO_NAME}?tab=settings"
          echo "   Settings ‚Üí Repository Tags ‚Üí Tag Expiration"

      # ============================================================================
      # DETERMINE ADVISORY SEVERITY
      # ============================================================================
      # Dynamically determine security advisory severity based on actual findings
      # in the comprehensive security report, rather than using hardcoded 'high'.

      - name: Determine advisory severity
        if: always() && hashFiles('security-report.md') != ''
        id: severity
        run: |
          # Check comprehensive report for critical/high findings
          if grep -q 'üî¥ CRITICAL' security-report.md || grep -q 'Critical:' security-report.md; then
            echo "severity=critical" >> $GITHUB_OUTPUT
            echo "üìä Detected CRITICAL findings - advisory severity: critical"
          elif grep -q 'üü† HIGH' security-report.md || grep -q 'High:' security-report.md; then
            echo "severity=high" >> $GITHUB_OUTPUT
            echo "üìä Detected HIGH findings - advisory severity: high"
          elif grep -q 'üü° MEDIUM' security-report.md || grep -q 'Medium:' security-report.md; then
            echo "severity=moderate" >> $GITHUB_OUTPUT
            echo "üìä Detected MEDIUM findings - advisory severity: moderate"
          else
            echo "severity=low" >> $GITHUB_OUTPUT
            echo "üìä No high-severity findings - advisory severity: low"
          fi
        continue-on-error: true

      # ============================================================================
      # AGGREGATE RESULTS
      # ============================================================================

      - name: Generate security scan summary
        if: always()
        env:
          GITLEAKS_OUTCOME: ${{ steps.gitleaks.outcome }}
          TRUFFLEHOG_OUTCOME: ${{ steps.trufflehog.outcome }}
          SEMGREP_OUTCOME: ${{ steps.semgrep.outcome }}
          SHELLCHECK_OUTCOME: ${{ steps.shellcheck.outcome }}
          HADOLINT_OUTCOME: ${{ steps.hadolint.outcome }}
          YAMLLINT_OUTCOME: ${{ steps.yamllint.outcome }}
          ACTIONLINT_OUTCOME: ${{ steps.actionlint.outcome }}
          KUBELINTER_OUTCOME: ${{ steps.kubelinter.outcome }}
          RBAC_OUTCOME: ${{ steps.rbac_analyzer.outcome }}
        run: |
          # Function to extract severity summary from JSON (robust parsing with jq)
          get_severity_badge() {
            local tool_name="$1"
            local json_file="security-summary.json"

            if [[ ! -f "$json_file" ]]; then
              echo ""
              return
            fi

            # Verify jq is available
            if ! command -v jq &> /dev/null; then
              echo "<br/>‚ö†Ô∏è jq not available"
              return
            fi

            # Validate JSON structure before parsing
            if ! jq -e ".tools[\"$tool_name\"]" "$json_file" &>/dev/null; then
              echo ""
              return
            fi

            # Extract severity counts from JSON using jq
            local critical=$(jq -r ".tools[\"$tool_name\"].critical // 0" "$json_file")
            local high=$(jq -r ".tools[\"$tool_name\"].high // 0" "$json_file")
            local medium=$(jq -r ".tools[\"$tool_name\"].medium // 0" "$json_file")
            local low=$(jq -r ".tools[\"$tool_name\"].low // 0" "$json_file")
            local total=$(jq -r ".tools[\"$tool_name\"].total // 0" "$json_file")

            if [[ "$total" == "0" ]]; then
              echo ""
              return
            fi

            # Build severity summary with non-zero counts
            local summary=""
            [[ $critical -gt 0 ]] && summary="${summary}üî¥ Critical: $critical "
            [[ $high -gt 0 ]] && summary="${summary}üü† High: $high "
            [[ $medium -gt 0 ]] && summary="${summary}üü° Medium: $medium "
            [[ $low -gt 0 ]] && summary="${summary}üîµ Low: $low "

            # Trim trailing space
            summary="${summary% }"

            # Fallback: if no severity breakdown, just show total
            if [[ -z "$summary" ]]; then
              summary="$total issues"
            fi

            echo "<br/>$summary"
          }

          # Function to determine status based on outcome and output file validity
          get_status() {
            local outcome="$1"
            local output_file="$2"

            if [[ "$outcome" == "success" ]]; then
              echo "‚úÖ|Passed"
            elif [[ "$outcome" == "failure" ]]; then
              if [[ -f "$output_file" && -s "$output_file" ]]; then
                # Verify file is valid JSON/SARIF (for tools that produce such output)
                case "$output_file" in
                  trufflehog.json)
                    # TruffleHog outputs JSONL (JSON Lines), not a single JSON document
                    # Use -s to slurp all lines into an array for validation
                    if jq -s empty "$output_file" 2>/dev/null; then
                      echo "üîí|Issues Found"
                    else
                      echo "‚ùå|Failed (invalid JSONL output)"
                    fi
                    ;;
                  *.json)
                    if jq empty "$output_file" 2>/dev/null; then
                      echo "üîí|Issues Found"
                    else
                      echo "‚ùå|Failed (invalid JSON output)"
                    fi
                    ;;
                  *.sarif)
                    if jq empty "$output_file" 2>/dev/null; then
                      echo "üîí|Issues Found"
                    else
                      echo "‚ùå|Failed (invalid SARIF)"
                    fi
                    ;;
                  *)
                    # For text/markdown files like rbac-analysis.md
                    echo "üîí|Issues Found"
                    ;;
                esac
              else
                echo "‚ùå|Failed (no output or empty file)"
              fi
            elif [[ "$outcome" == "cancelled" ]]; then
              echo "üö´|Cancelled"
            elif [[ "$outcome" == "skipped" ]]; then
              echo "‚è≠Ô∏è|Skipped"
            else
              echo "‚ùì|Unknown"
            fi
          }

          echo "## üîí Security Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Tool | Purpose | Status | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|------|---------|--------|--------|" >> $GITHUB_STEP_SUMMARY

          # Gitleaks
          status_result=$(get_status "$GITLEAKS_OUTCOME" "gitleaks.json")
          severity_summary=$(get_severity_badge "Gitleaks")
          echo "| Gitleaks | Secrets detection (pattern-based) | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # TruffleHog
          status_result=$(get_status "$TRUFFLEHOG_OUTCOME" "trufflehog.json")
          severity_summary=$(get_severity_badge "TruffleHog")
          echo "| TruffleHog | Secrets detection (verified, 800+ types) | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # Semgrep
          status_result=$(get_status "$SEMGREP_OUTCOME" "semgrep.sarif")
          severity_summary=$(get_severity_badge "Semgrep")
          echo "| Semgrep | Custom security rules (27 operator-focused) | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # ShellCheck
          status_result=$(get_status "$SHELLCHECK_OUTCOME" "shellcheck.json")
          severity_summary=$(get_severity_badge "ShellCheck")
          echo "| ShellCheck | Shell script security | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # Hadolint
          status_result=$(get_status "$HADOLINT_OUTCOME" "hadolint.sarif")
          severity_summary=$(get_severity_badge "Hadolint")
          echo "| Hadolint | Dockerfile security | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # yamllint
          status_result=$(get_status "$YAMLLINT_OUTCOME" "yamllint.txt")
          severity_summary=$(get_severity_badge "yamllint")
          echo "| yamllint | YAML validation | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # actionlint
          status_result=$(get_status "$ACTIONLINT_OUTCOME" "actionlint.txt")
          severity_summary=$(get_severity_badge "actionlint")
          echo "| actionlint | GitHub Actions workflow validation | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # kube-linter
          status_result=$(get_status "$KUBELINTER_OUTCOME" "kube-linter.json")
          severity_summary=$(get_severity_badge "kube-linter")
          echo "| kube-linter | Kubernetes manifest security (36 checks) | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # RBAC Analyzer
          status_result=$(get_status "$RBAC_OUTCOME" "rbac-analysis.md")
          severity_summary=$(get_severity_badge "RBAC Analyzer")
          echo "| RBAC Analyzer | Privilege chain analysis | ${status_result%%|*} | ${status_result##*|}${severity_summary} |" >> $GITHUB_STEP_SUMMARY

          # Overall status
          echo "" >> $GITHUB_STEP_SUMMARY
          if [[ "$GITLEAKS_OUTCOME" == "success" ]] && \
             [[ "$TRUFFLEHOG_OUTCOME" == "success" ]] && \
             [[ "$SEMGREP_OUTCOME" == "success" ]] && \
             [[ "$SHELLCHECK_OUTCOME" == "success" ]] && \
             [[ "$HADOLINT_OUTCOME" == "success" ]] && \
             [[ "$YAMLLINT_OUTCOME" == "success" ]] && \
             [[ "$ACTIONLINT_OUTCOME" == "success" ]] && \
             [[ "$KUBELINTER_OUTCOME" == "success" ]] && \
             [[ "$RBAC_OUTCOME" == "success" ]]; then
            echo "‚úÖ **All security scans passed - no issues found**" >> $GITHUB_STEP_SUMMARY
          else
            # Check if any tools actually failed (vs just found issues)
            has_failures=false
            has_incomplete=false
            for outcome in "$GITLEAKS_OUTCOME" "$TRUFFLEHOG_OUTCOME" "$SEMGREP_OUTCOME" "$SHELLCHECK_OUTCOME" "$HADOLINT_OUTCOME" "$YAMLLINT_OUTCOME" "$ACTIONLINT_OUTCOME" "$KUBELINTER_OUTCOME" "$RBAC_OUTCOME"; do
              if [[ "$outcome" == "failure" ]]; then
                # At least one tool had a non-success outcome (either failed or found issues)
                has_failures=true
              elif [[ "$outcome" == "cancelled" || "$outcome" == "skipped" ]]; then
                # At least one tool was cancelled or skipped
                has_incomplete=true
              fi
            done

            if $has_failures; then
              echo "‚ö†Ô∏è **Security issues detected - review required**" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Use \`/sec-scan:show-report\` command to view detailed findings from Quay.io." >> $GITHUB_STEP_SUMMARY
            elif $has_incomplete; then
              echo "‚ÑπÔ∏è **Security scans incomplete - review required**" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "Some scans were cancelled or skipped. Review the workflow logs for details." >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Fail workflow on critical/high findings
        if: always() && hashFiles('security-summary.json') != ''
        run: |
          # Verify jq is available
          if ! command -v jq &> /dev/null; then
            echo "‚ö†Ô∏è jq not available - skipping critical findings check"
            exit 0
          fi

          critical=$(jq -r '.severity_counts.critical // 0' security-summary.json)
          high=$(jq -r '.severity_counts.high // 0' security-summary.json)

          # Validate numeric values
          if [[ "$critical" =~ ^[0-9]+$ ]] && [[ $critical -gt 0 ]]; then
            echo "::error::$critical CRITICAL security findings detected - review security report for details"
            echo ""
            echo "‚ùå Workflow failed: $critical CRITICAL findings detected"
            echo ""
            echo "Next steps:"
            echo "  1. View report: /sec-scan:show-report --latest"
            echo "  2. Review critical findings in security-report.md"
            echo "  3. Fix vulnerabilities or acknowledge false positives using /sec-scan:acknowledge command"
            exit 1
          fi

          if [[ "$high" =~ ^[0-9]+$ ]] && [[ $high -gt 0 ]]; then
            echo "::error::$high HIGH severity findings detected - review security report for details"
            echo ""
            echo "‚ùå Workflow failed: $high HIGH severity findings detected"
            echo ""
            echo "Next steps:"
            echo "  1. View report: /sec-scan:show-report --latest"
            echo "  2. Review high severity findings in security-report.md"
            echo "  3. Fix vulnerabilities or acknowledge false positives using /sec-scan:acknowledge command"
            exit 1
          fi

      # ============================================================================
      # CREATE SECURITY ADVISORY ON CRITICAL FINDINGS
      # ============================================================================
      # Only triggered by critical security tools (secrets detection, SAST, RBAC analysis).
      # Excluded: linters (yamllint, shellcheck, hadolint) - these flag style/best-practices.
      # Severity is determined dynamically from the comprehensive security report.
      #
      # GitHub App Authentication:
      # - Requires a GitHub App with repository_advisories:write permission
      # - GITHUB_TOKEN does not support the repository_advisories permission scope
      # - App credentials (App ID and Private Key) must be stored as repository secrets
      # - Uses continue-on-error to allow workflow to complete even if secrets are missing

      - name: Check if GitHub App secrets are configured
        id: check_app_secrets
        env:
          APP_ID: ${{ secrets.SECURITY_APP_ID }}
          APP_KEY: ${{ secrets.SECURITY_APP_PRIVATE_KEY }}
        run: |
          if [ -n "$APP_ID" ] && [ -n "$APP_KEY" ]; then
            echo "configured=true" >> $GITHUB_OUTPUT
          else
            echo "configured=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è  GitHub App credentials not configured - security advisory creation disabled"
          fi

      - name: Generate GitHub App token
        if: |
          steps.check_app_secrets.outputs.configured == 'true' &&
          (inputs.test_advisory == true ||
           steps.gitleaks.outcome == 'failure' ||
           steps.trufflehog.outcome == 'failure' ||
           steps.semgrep.outcome == 'failure' ||
           steps.rbac_analyzer.outcome == 'failure')
        id: app_token
        continue-on-error: true
        uses: actions/create-github-app-token@5d869da34e18e7287c1daad50e0b8ea0f506ce69  # v1.11.0
        with:
          app-id: ${{ secrets.SECURITY_APP_ID }}
          private-key: ${{ secrets.SECURITY_APP_PRIVATE_KEY }}
          owner: ${{ github.repository_owner }}
          repositories: ${{ github.event.repository.name }}

      - name: Create private security advisory on critical findings
        if: |
          steps.app_token.outcome == 'success' &&
          (inputs.test_advisory == true ||
           steps.gitleaks.outcome == 'failure' ||
           steps.trufflehog.outcome == 'failure' ||
           steps.semgrep.outcome == 'failure' ||
           steps.rbac_analyzer.outcome == 'failure')
        uses: actions/github-script@f28e40c7f34bde8b3046d885e986cb6290c5673b  # v7.0.1
        with:
          github-token: ${{ steps.app_token.outputs.token }}
          script: |
            const createAdvisory = require('./.github/scripts/create-security-advisory.js')
            await createAdvisory({
              github,
              context,
              core,
              severity: '${{ steps.severity.outputs.severity || 'high' }}',
              workflowRunUrl: '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}',
              commit: '${{ github.sha }}',
              branch: '${{ github.ref_name }}'
            })

      # ============================================================================
      # CLEANUP SENSITIVE FILES
      # ============================================================================
      # Remove temporary baseline file that contains vulnerability acknowledgment data
      # This prevents sensitive information from persisting on the runner or in logs

      - name: Clean up temporary baseline file
        if: always()
        run: |
          if [ -f /tmp/baseline.yaml ]; then
            rm -f /tmp/baseline.yaml
            echo "‚úÖ Cleaned up temporary baseline file"
          fi
